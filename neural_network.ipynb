{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMq3czIIInJ0",
        "outputId": "6dc7f582-5e26-4c63-b7b6-40b1ed5d4fd7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "bs4YJFSEIg7t",
        "outputId": "3adbbcbb-3edd-4a1c-da80-c73b484e5e68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 1), output.shape=(None, 24)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e15f22da0b04>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    661\u001b[0m                 \u001b[0;34m\"Arguments `target` and `output` must have the same shape. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0;34m\"Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 1), output.shape=(None, 24)"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Load Data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/DBDA_PROJECT/Formula1DataAnalytics-main/Main/data/main_data/dataframe.csv\")  # Replace with actual data path\n",
        "\n",
        "# Preprocessing\n",
        "X = data.drop(columns=[\"position\"])  # Replace \"target\" with actual target column\n",
        "y = data[\"position\"]\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Apply one-hot encoding to categorical features\n",
        "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X and y are your full dataset\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Build Neural Network\n",
        "# Define model architecture\n",
        "input_dim = X_train.shape[1]\n",
        "num_classes = len(np.unique(y_train))  # Ensure y_train is defined\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(input_dim,)),  # Ensure input shape matches your data\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(num_classes, activation='softmax')  # Ensure num_classes is set correctly\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Learning rate scheduler\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_scheduler]\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Load Data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/DBDA_PROJECT/Formula1DataAnalytics-main/Main/data/main_data/dataframe.csv\")  # Replace with actual data path\n",
        "\n",
        "# Preprocessing\n",
        "X = data.drop(columns=[\"position\"])  # Feature columns\n",
        "y = data[\"position\"]  # Target column\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Apply one-hot encoding to categorical features\n",
        "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Encode target labels\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)  # Converts categories into integers\n",
        "\n",
        "# One-hot encode labels for categorical crossentropy\n",
        "y_one_hot = to_categorical(y_encoded)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_one_hot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model Architecture\n",
        "input_dim = X_train.shape[1]\n",
        "num_classes = y_one_hot.shape[1]  # Number of unique classes\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(input_dim,)),  # Input layer\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(num_classes, activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Learning rate scheduler\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),  # Using test set for validation\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_scheduler],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot to labels\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n",
        "print(confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5k4X2QcPn1A",
        "outputId": "dd3c598a-4dfa-4c8c-e3c0-1a49f8185d02"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.0498 - loss: 4.0362 - val_accuracy: 0.1052 - val_loss: 3.0197 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1453 - loss: 3.0428 - val_accuracy: 0.1133 - val_loss: 2.8899 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.1954 - loss: 2.6416 - val_accuracy: 0.1087 - val_loss: 2.8266 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2404 - loss: 2.4603 - val_accuracy: 0.1087 - val_loss: 2.8035 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.2613 - loss: 2.3048 - val_accuracy: 0.1110 - val_loss: 2.8098 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.2941 - loss: 2.1960 - val_accuracy: 0.0983 - val_loss: 2.7935 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3236 - loss: 2.0425 - val_accuracy: 0.0855 - val_loss: 2.7576 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3556 - loss: 1.9245 - val_accuracy: 0.0855 - val_loss: 2.7559 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3745 - loss: 1.8612 - val_accuracy: 0.0902 - val_loss: 2.7527 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4137 - loss: 1.7307 - val_accuracy: 0.0867 - val_loss: 2.7660 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4234 - loss: 1.7042 - val_accuracy: 0.0890 - val_loss: 2.7746 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m50/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4681 - loss: 1.5506\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4654 - loss: 1.5578 - val_accuracy: 0.0890 - val_loss: 2.8027 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4931 - loss: 1.5320 - val_accuracy: 0.0855 - val_loss: 2.8117 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5120 - loss: 1.4544 - val_accuracy: 0.0902 - val_loss: 2.8370 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m51/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5286 - loss: 1.4128\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5270 - loss: 1.4148 - val_accuracy: 0.0832 - val_loss: 2.8635 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5344 - loss: 1.3390 - val_accuracy: 0.0763 - val_loss: 2.8752 - learning_rate: 2.5000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5660 - loss: 1.3011 - val_accuracy: 0.0740 - val_loss: 2.8870 - learning_rate: 2.5000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5574 - loss: 1.2927\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5574 - loss: 1.2929 - val_accuracy: 0.0728 - val_loss: 2.9026 - learning_rate: 2.5000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5892 - loss: 1.2442 - val_accuracy: 0.0740 - val_loss: 2.9051 - learning_rate: 1.2500e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5732 - loss: 1.2624 - val_accuracy: 0.0751 - val_loss: 2.9206 - learning_rate: 1.2500e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5898 - loss: 1.2364\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5899 - loss: 1.2364 - val_accuracy: 0.0705 - val_loss: 2.9369 - learning_rate: 1.2500e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6066 - loss: 1.2051 - val_accuracy: 0.0705 - val_loss: 2.9410 - learning_rate: 6.2500e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6050 - loss: 1.1754 - val_accuracy: 0.0751 - val_loss: 2.9470 - learning_rate: 6.2500e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5983 - loss: 1.2108\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5984 - loss: 1.2106 - val_accuracy: 0.0740 - val_loss: 2.9507 - learning_rate: 6.2500e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5938 - loss: 1.2068 - val_accuracy: 0.0728 - val_loss: 2.9540 - learning_rate: 3.1250e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6046 - loss: 1.1925 - val_accuracy: 0.0728 - val_loss: 2.9580 - learning_rate: 3.1250e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m50/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6199 - loss: 1.1868\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6204 - loss: 1.1856 - val_accuracy: 0.0717 - val_loss: 2.9609 - learning_rate: 3.1250e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6241 - loss: 1.1828 - val_accuracy: 0.0717 - val_loss: 2.9629 - learning_rate: 1.5625e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6064 - loss: 1.2096 - val_accuracy: 0.0728 - val_loss: 2.9649 - learning_rate: 1.5625e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m50/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6263 - loss: 1.1606\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6263 - loss: 1.1599 - val_accuracy: 0.0728 - val_loss: 2.9643 - learning_rate: 1.5625e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6325 - loss: 1.1675 - val_accuracy: 0.0728 - val_loss: 2.9650 - learning_rate: 7.8125e-06\n",
            "Epoch 32/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6012 - loss: 1.1894 - val_accuracy: 0.0740 - val_loss: 2.9662 - learning_rate: 7.8125e-06\n",
            "Epoch 33/50\n",
            "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6247 - loss: 1.1868\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6248 - loss: 1.1859 - val_accuracy: 0.0717 - val_loss: 2.9677 - learning_rate: 7.8125e-06\n",
            "Epoch 34/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6279 - loss: 1.1585 - val_accuracy: 0.0728 - val_loss: 2.9684 - learning_rate: 3.9063e-06\n",
            "Epoch 35/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6322 - loss: 1.1799 - val_accuracy: 0.0751 - val_loss: 2.9676 - learning_rate: 3.9063e-06\n",
            "Epoch 36/50\n",
            "\u001b[1m50/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6184 - loss: 1.1533\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6187 - loss: 1.1539 - val_accuracy: 0.0728 - val_loss: 2.9652 - learning_rate: 3.9063e-06\n",
            "Epoch 37/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6154 - loss: 1.1610 - val_accuracy: 0.0717 - val_loss: 2.9653 - learning_rate: 1.9531e-06\n",
            "Epoch 38/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6098 - loss: 1.1737 - val_accuracy: 0.0717 - val_loss: 2.9670 - learning_rate: 1.9531e-06\n",
            "Epoch 39/50\n",
            "\u001b[1m50/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6087 - loss: 1.1898\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6088 - loss: 1.1895 - val_accuracy: 0.0728 - val_loss: 2.9657 - learning_rate: 1.9531e-06\n",
            "Epoch 40/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6224 - loss: 1.1659 - val_accuracy: 0.0705 - val_loss: 2.9666 - learning_rate: 9.7656e-07\n",
            "Epoch 41/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6295 - loss: 1.1689 - val_accuracy: 0.0694 - val_loss: 2.9688 - learning_rate: 9.7656e-07\n",
            "Epoch 42/50\n",
            "\u001b[1m50/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6186 - loss: 1.1656\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6189 - loss: 1.1658 - val_accuracy: 0.0740 - val_loss: 2.9670 - learning_rate: 9.7656e-07\n",
            "Epoch 43/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6260 - loss: 1.1569 - val_accuracy: 0.0740 - val_loss: 2.9653 - learning_rate: 4.8828e-07\n",
            "Epoch 44/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6153 - loss: 1.1648 - val_accuracy: 0.0740 - val_loss: 2.9675 - learning_rate: 4.8828e-07\n",
            "Epoch 45/50\n",
            "\u001b[1m52/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6375 - loss: 1.1347\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6366 - loss: 1.1366 - val_accuracy: 0.0728 - val_loss: 2.9671 - learning_rate: 4.8828e-07\n",
            "Epoch 46/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6163 - loss: 1.1636 - val_accuracy: 0.0740 - val_loss: 2.9684 - learning_rate: 2.4414e-07\n",
            "Epoch 47/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6131 - loss: 1.1710 - val_accuracy: 0.0728 - val_loss: 2.9664 - learning_rate: 2.4414e-07\n",
            "Epoch 48/50\n",
            "\u001b[1m54/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6239 - loss: 1.1583\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6236 - loss: 1.1587 - val_accuracy: 0.0728 - val_loss: 2.9677 - learning_rate: 2.4414e-07\n",
            "Epoch 49/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6252 - loss: 1.1592 - val_accuracy: 0.0728 - val_loss: 2.9687 - learning_rate: 1.2207e-07\n",
            "Epoch 50/50\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5949 - loss: 1.1983 - val_accuracy: 0.0728 - val_loss: 2.9711 - learning_rate: 1.2207e-07\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.29      0.30        38\n",
            "           1       0.10      0.11      0.10        38\n",
            "           2       0.09      0.10      0.09        40\n",
            "           3       0.00      0.00      0.00        49\n",
            "           4       0.04      0.07      0.05        30\n",
            "           5       0.10      0.09      0.10        45\n",
            "           6       0.00      0.00      0.00        32\n",
            "           7       0.06      0.04      0.05        51\n",
            "           8       0.03      0.03      0.03        40\n",
            "           9       0.02      0.03      0.02        40\n",
            "          10       0.03      0.02      0.03        41\n",
            "          11       0.00      0.00      0.00        45\n",
            "          12       0.00      0.00      0.00        34\n",
            "          13       0.06      0.05      0.05        42\n",
            "          14       0.00      0.00      0.00        47\n",
            "          15       0.02      0.02      0.02        41\n",
            "          16       0.04      0.05      0.05        43\n",
            "          17       0.03      0.02      0.03        42\n",
            "          18       0.17      0.22      0.19        32\n",
            "          19       0.33      0.18      0.24        38\n",
            "          20       0.10      0.12      0.11        16\n",
            "          21       0.38      0.30      0.33        20\n",
            "          22       0.23      0.33      0.27         9\n",
            "          23       0.40      0.17      0.24        12\n",
            "\n",
            "    accuracy                           0.07       865\n",
            "   macro avg       0.11      0.09      0.09       865\n",
            "weighted avg       0.08      0.07      0.08       865\n",
            "\n",
            "[[11 17  7  2  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [13  4 10  6  2  1  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
            " [ 6 10  4  3 11  1  3  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 5  5 12  0 17  5  2  1  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  2  6  9  2  5  2  3  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  3  5  5  8  4  9  7  2  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  7  8  0  3  8  4  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  1  1  0  3  6 12  2  5  7 11  0  3  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  4  6  5  1 14  3  2  3  0  1  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  2  0  1  1  4  5  1  8  4  3  5  3  1  1  0  1  0  0  0  0  0]\n",
            " [ 0  0  1  0  2  0  3  2  3 12  1  6  5  1  2  2  0  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  0  1  1  3 11  5  0 10  4  4  1  3  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  2  0  1  3  3  9  2  0  3  5  2  3  1  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  1  0  0  4  2  6  8  2  5  3  8  1  0  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  2  0  3 11  9  0 10  5  3  1  1  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  2  0  3  6  3  4  1  9 10  1  1  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  1  0  2  5  6  8 11  2  5  2  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0  1  0  0  0  3  3  3 10 10  1  9  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  5  3  2  5  7  7  2  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  1  0  0  0  0  1  0  1  3  1  5 12  7  5  2  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5  4  2  3  2  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  3  1  5  6  3  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  2  3  3]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  3  5  2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE  # To handle class imbalance\n",
        "\n",
        "# Load Data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/DBDA_PROJECT/Formula1DataAnalytics-main/Main/data/main_data/dataframe.csv\")  # Replace with actual data path\n",
        "\n",
        "# Preprocessing\n",
        "X = data.drop(columns=[\"position\"])  # Feature columns\n",
        "y = data[\"position\"]  # Target column\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Apply one-hot encoding to categorical features\n",
        "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Scale numerical features using MinMaxScaler (better for deep learning)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Encode target labels\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)  # Converts categories into integers\n",
        "\n",
        "# One-hot encode labels for categorical crossentropy\n",
        "y_one_hot = to_categorical(y_encoded)\n",
        "\n",
        "# Handle Class Imbalance using SMOTE (Synthetic Minority Oversampling)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_encoded)\n",
        "y_resampled_one_hot = to_categorical(y_resampled)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled_one_hot, test_size=0.2, random_state=42, stratify=y_resampled)\n",
        "\n",
        "# Model Architecture\n",
        "input_dim = X_train.shape[1]\n",
        "num_classes = y_resampled_one_hot.shape[1]  # Number of unique classes\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(input_dim,)),  # Input layer\n",
        "    Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(num_classes, activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "optimizer = AdamW(learning_rate=0.001, weight_decay=1e-5)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks: Learning Rate Reduction & Early Stopping\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    callbacks=[lr_scheduler, early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot to labels\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n",
        "print(confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PhaV3d-R__z",
        "outputId": "61e3a3bf-e15c-4e02-e571-3dd40ef6dc21"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.0730 - loss: 5.5515 - val_accuracy: 0.1617 - val_loss: 4.5287 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.2046 - loss: 4.5247 - val_accuracy: 0.1876 - val_loss: 4.2630 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.2510 - loss: 4.1527 - val_accuracy: 0.2073 - val_loss: 4.1419 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.2743 - loss: 3.9621 - val_accuracy: 0.2041 - val_loss: 4.0719 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.3399 - loss: 3.7354 - val_accuracy: 0.2093 - val_loss: 3.9906 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.3535 - loss: 3.6148 - val_accuracy: 0.2104 - val_loss: 3.9183 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.3940 - loss: 3.4380 - val_accuracy: 0.2249 - val_loss: 3.8504 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.4054 - loss: 3.3532 - val_accuracy: 0.2363 - val_loss: 3.8536 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.4535 - loss: 3.2103 - val_accuracy: 0.2280 - val_loss: 3.8237 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.4751 - loss: 3.0989 - val_accuracy: 0.2342 - val_loss: 3.7926 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.5009 - loss: 3.0025 - val_accuracy: 0.2332 - val_loss: 3.8347 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.5032 - loss: 2.9304 - val_accuracy: 0.2218 - val_loss: 3.8443 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5601 - loss: 2.7748\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5597 - loss: 2.7756 - val_accuracy: 0.2332 - val_loss: 3.8937 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5947 - loss: 2.6440 - val_accuracy: 0.2321 - val_loss: 3.8859 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6365 - loss: 2.5197 - val_accuracy: 0.2197 - val_loss: 3.9376 - learning_rate: 5.0000e-04\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.57      0.39        40\n",
            "           1       0.09      0.07      0.08        40\n",
            "           2       0.10      0.05      0.07        40\n",
            "           3       0.08      0.12      0.10        40\n",
            "           4       0.08      0.05      0.06        40\n",
            "           5       0.10      0.07      0.08        40\n",
            "           6       0.06      0.05      0.05        41\n",
            "           7       0.05      0.05      0.05        41\n",
            "           8       0.11      0.10      0.11        40\n",
            "           9       0.15      0.28      0.19        40\n",
            "          10       0.00      0.00      0.00        41\n",
            "          11       0.07      0.10      0.08        40\n",
            "          12       0.05      0.05      0.05        40\n",
            "          13       0.07      0.07      0.07        40\n",
            "          14       0.09      0.07      0.08        41\n",
            "          15       0.07      0.05      0.06        40\n",
            "          16       0.10      0.15      0.12        40\n",
            "          17       0.20      0.17      0.19        40\n",
            "          18       0.36      0.23      0.28        40\n",
            "          19       0.33      0.15      0.20        41\n",
            "          20       0.52      0.68      0.59        40\n",
            "          21       0.62      0.62      0.62        40\n",
            "          22       0.92      0.88      0.90        40\n",
            "          23       0.87      1.00      0.93        40\n",
            "\n",
            "    accuracy                           0.23       965\n",
            "   macro avg       0.22      0.24      0.22       965\n",
            "weighted avg       0.22      0.23      0.22       965\n",
            "\n",
            "[[23 10  2  4  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [23  3  1 11  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
            " [14  6  2 12  1  2  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 5  8  6  5  6  4  4  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 4  5  6 13  2  2  5  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 7  0  2  7  7  3  6  7  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 2  1  2  4  6  4  2 10  7  2  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  2  2  5  7  2  8 12  1  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  2  5  6  4 13  2  3  4  0  0  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  1  1  5  2  3  6 11  2  2  2  3  1  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  2  3  5 13  0  7  3  1  4  1  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  2  0 12  3  4  5  7  2  2  1  1  1  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  1  4  4  4 13  2  5  2  2  3  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  2  0 10  9  3  4  4  5  2  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  2  1  7  5  5  3  5  9  4  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  3  1  1  4  8  5  2 12  3  0  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  1  2  2  7  6  6  6  5  2  0  2  1  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  1  2  0  2  4  1 18  7  2  2  0  1  0  0]\n",
            " [ 0  0  0  0  0  1  1  0  0  0  0  0  1  2  2  3  2  7  9  7  4  1  0  0]\n",
            " [ 1  0  0  1  0  1  0  0  0  0  0  0  0  0  1  2  0  4 10  6 11  4  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  2 27  7  2  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  1  1  1  7 25  1  2]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 35  4]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 40]]\n"
          ]
        }
      ]
    }
  ]
}